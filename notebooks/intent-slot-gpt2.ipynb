{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport transformers\nimport json\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm\nimport copy\n\nimport pandas as pd\n\nimport os\nos.environ['TOKENIZERS_PARALLELISM'] = 'true'","metadata":{"_uuid":"5eacec07-e35e-479f-909d-c3f17bcd856b","_cell_guid":"40dc9573-c59d-4232-8cd4-0aef803ef5c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-11T15:00:33.600082Z","iopub.execute_input":"2023-04-11T15:00:33.600728Z","iopub.status.idle":"2023-04-11T15:00:37.902854Z","shell.execute_reply.started":"2023-04-11T15:00:33.600698Z","shell.execute_reply":"2023-04-11T15:00:37.900556Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class SlotIntentDataset(Dataset):\n    \n    def __init__(self, datapath):\n        self.data = []\n        with open(datapath, 'r') as jsonl_file:\n            for line in jsonl_file:\n                self.data.append(json.loads(line))\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return (self.data[idx]['input'], \", \".join(self.data[idx]['user_contacts']), self.data[idx]['output'])\n\ndef dl_collate_fn(batch):\n    return list(batch)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:00:37.907706Z","iopub.execute_input":"2023-04-11T15:00:37.908773Z","iopub.status.idle":"2023-04-11T15:00:37.932452Z","shell.execute_reply.started":"2023-04-11T15:00:37.908736Z","shell.execute_reply":"2023-04-11T15:00:37.927159Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndata_path = '/kaggle/input/col772a3-data/A3'","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:07:03.684351Z","iopub.execute_input":"2023-04-11T15:07:03.684932Z","iopub.status.idle":"2023-04-11T15:07:03.690934Z","shell.execute_reply.started":"2023-04-11T15:07:03.684860Z","shell.execute_reply":"2023-04-11T15:07:03.689773Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_ds = SlotIntentDataset(f'{data_path}/train.jsonl')\nval_ds = SlotIntentDataset(f'{data_path}/dev.jsonl')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:07:53.900724Z","iopub.execute_input":"2023-04-11T15:07:53.901179Z","iopub.status.idle":"2023-04-11T15:08:06.029663Z","shell.execute_reply.started":"2023-04-11T15:07:53.901124Z","shell.execute_reply":"2023-04-11T15:08:06.028581Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"DEBUG = True\nif DEBUG:\n    train_ds.data = train_ds.data[:128]\n    val_ds.data = val_ds.data[:512]","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:08:06.031828Z","iopub.execute_input":"2023-04-11T15:08:06.032396Z","iopub.status.idle":"2023-04-11T15:08:06.151482Z","shell.execute_reply.started":"2023-04-11T15:08:06.032346Z","shell.execute_reply":"2023-04-11T15:08:06.150228Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size=16, num_workers=2, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=16, num_workers=2, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:08:06.153650Z","iopub.execute_input":"2023-04-11T15:08:06.154050Z","iopub.status.idle":"2023-04-11T15:08:06.162442Z","shell.execute_reply.started":"2023-04-11T15:08:06.154009Z","shell.execute_reply":"2023-04-11T15:08:06.161219Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/intent-slot-gpt2/intent-slot-gpt2.pt', map_location=device)# transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ntokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n# optimizer = optim.Adam(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:00:55.920565Z","iopub.execute_input":"2023-04-11T15:00:55.920960Z","iopub.status.idle":"2023-04-11T15:01:08.937099Z","shell.execute_reply.started":"2023-04-11T15:00:55.920922Z","shell.execute_reply":"2023-04-11T15:01:08.935888Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95581a61ede0484683040389a84e055c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4d86027c274d69981e6ce6e0c650d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2083da8a4b034a7bb9462c6490217cef"}},"metadata":{}}]},{"cell_type":"code","source":"def process_batch(batch, tokenizer):\n    encoder_strs = [f'[{b}] {a}: {c}' for a,b,c in zip(batch[0], batch[1], batch[2])]\n\n    return tokenizer(encoder_strs, return_tensors=\"pt\", padding=True, truncation=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:01:08.939742Z","iopub.execute_input":"2023-04-11T15:01:08.941452Z","iopub.status.idle":"2023-04-11T15:01:08.948247Z","shell.execute_reply.started":"2023-04-11T15:01:08.941408Z","shell.execute_reply":"2023-04-11T15:01:08.946748Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(model, tokenizer, train_dl, val_dl, optimizer, scheduler=None, max_epochs=20, patience_lim=2):\n\n    best_model = None\n    best_val_loss = 10000\n    val_losses = []\n    train_losses = []\n    patience = 0\n\n    for epoch in range(max_epochs):\n\n        print(f'Epoch {epoch}:')\n        train_loss = torch.tensor(0, dtype=torch.float, device=device)\n        model.train()\n        for batch in tqdm(train_dl):\n            proc_batch = process_batch(batch, tokenizer)\n            \n            optimizer.zero_grad()\n            loss = model(**proc_batch, labels=proc_batch['input_ids']).loss\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.detach()\n        \n        if scheduler:\n            scheduler.step()\n\n        train_loss = train_loss.cpu()\n        train_loss /= len(train_dl)\n        print(f' Train Loss: {train_loss}')\n        train_losses.append(train_loss)\n\n        val_loss = torch.tensor(0, dtype=torch.float, device=device)\n        true_labels = []\n        pred_labels = []\n        model.eval()\n        for batch in tqdm(val_dl):\n            proc_batch = process_batch(batch, tokenizer)\n            \n            loss = model(**proc_batch, labels=proc_batch['input_ids']).loss\n\n            val_loss += loss.detach()\n            \n        val_loss = val_loss.cpu()\n        val_loss /= len(val_dl)\n        val_losses.append(val_loss)\n\n        print(f' Val Loss: {val_loss}')\n        print('')\n\n        # early stopping\n        if val_loss >= best_val_loss:\n            if patience >= patience_lim:\n                break\n            else:\n                patience += 1\n        else:\n            patience = 0\n            best_val_loss = val_loss\n            best_model = copy.deepcopy(model)\n            best_model = best_model.cpu()\n            print(f'best model: {epoch}')\n    \n    return best_model, (train_losses, val_losses)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T14:33:04.820948Z","iopub.execute_input":"2023-04-10T14:33:04.821797Z","iopub.status.idle":"2023-04-10T14:33:04.836579Z","shell.execute_reply.started":"2023-04-10T14:33:04.821740Z","shell.execute_reply":"2023-04-10T14:33:04.835641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model, (train_losses, val_losses) = train(model, tokenizer, train_dl, val_dl, optimizer)\ntorch.save(best_model, 'intent-slot-gpt2.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(train_losses)\nplt.plot(val_losses)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate(model, tokenizer, dl):\n\n    pred_gens = []\n    gold_gens = []\n    \n    model.eval()\n    for batch in tqdm(dl):\n        encoder_toks = process_batch_eval(batch, tokenizer)\n        enc_len = encoder_toks['input_ids'].size(1)\n\n        # beam search generations for syntax rather than nucleus sample\n        gen = model.generate(\n            **encoder_toks,\n            num_beams=5,\n            max_new_tokens=100,\n        )\n        \n        pred_gens += tokenizer.batch_decode(gen[:,enc_len:], skip_special_tokens=True)\n        gold_gens += batch[2]\n    \n    return pred_gens, gold_gens","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:06:08.179489Z","iopub.execute_input":"2023-04-11T15:06:08.180269Z","iopub.status.idle":"2023-04-11T15:06:08.190380Z","shell.execute_reply.started":"2023-04-11T15:06:08.180220Z","shell.execute_reply":"2023-04-11T15:06:08.189249Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"eval_tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side='left')\neval_tokenizer.pad_token = eval_tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:06:08.396449Z","iopub.execute_input":"2023-04-11T15:06:08.397046Z","iopub.status.idle":"2023-04-11T15:06:18.737809Z","shell.execute_reply.started":"2023-04-11T15:06:08.397009Z","shell.execute_reply":"2023-04-11T15:06:18.736302Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def process_batch_eval(batch, tokenizer):\n    encoder_strs = [f'[{b}] {a}: \\xa0' for a,b,c in zip(batch[0], batch[1], batch[2])]\n\n    return tokenizer(encoder_strs, return_tensors=\"pt\", padding=True, truncation=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:06:18.744556Z","iopub.execute_input":"2023-04-11T15:06:18.747696Z","iopub.status.idle":"2023-04-11T15:06:18.758147Z","shell.execute_reply.started":"2023-04-11T15:06:18.747641Z","shell.execute_reply":"2023-04-11T15:06:18.756904Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pred_gens, gold_gens = generate(model, eval_tokenizer, val_dl)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:08:06.165438Z","iopub.execute_input":"2023-04-11T15:08:06.165806Z","iopub.status.idle":"2023-04-11T15:08:50.170996Z","shell.execute_reply.started":"2023-04-11T15:08:06.165771Z","shell.execute_reply":"2023-04-11T15:08:50.169746Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56d384f7cda949eab6444c48764ed282"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"def matches(y1, y2):\n    return (\"\".join(y1.split()) == \"\".join(y2.split()))\n\ndef exact_match_metric(gold, pred):\n    cnt_correct = 0\n    for i in range(len(gold)):\n        if(matches(gold[i], pred[i])):\n            \n            cnt_correct += 1\n    return cnt_correct/len(gold)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:08:50.175059Z","iopub.execute_input":"2023-04-11T15:08:50.175869Z","iopub.status.idle":"2023-04-11T15:08:50.185980Z","shell.execute_reply.started":"2023-04-11T15:08:50.175825Z","shell.execute_reply":"2023-04-11T15:08:50.184802Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"exact_match_metric(gold_gens, pred_gens)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T15:08:50.187146Z","iopub.execute_input":"2023-04-11T15:08:50.187665Z","iopub.status.idle":"2023-04-11T15:08:50.200733Z","shell.execute_reply.started":"2023-04-11T15:08:50.187626Z","shell.execute_reply":"2023-04-11T15:08:50.199420Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.712890625"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}